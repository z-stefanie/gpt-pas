export DISABLE_ADDMM_CUDA_LT=1
deepspeed psalm/train/train.py \
    --deepspeed ./scripts/zero2.json \
    --model_name_or_path "/home/hk/yyma/data/phi-1_5_dev" \
    --version "llava_phi" \
    --region_json_path "/path/to/coco_interactive_train_psalm.json" \
    --panoptic_json_path "/path/to/coco" \
    --ref_coco_path "/path/to/refcoco/refcoco_train.json" \
    --ref_coco_plus_path "/path/to/refcoco+/refcoco+_train.json" \
    --ref_coco_g_path "/path/to/refcocog/refcocog_train.json" \
    --image_folder "/path/to/coco/train2017" \
    --refcoco_image_folder "/path/to/coco/train2014" \
    --mmconv_path "/path/to/llava_1_5" \
    --vision_tower "/path/to/model.pkl" \
    --pretrain_mm_mlp_adapter "/path/to/mm_projector.bin" \
    --mm_vision_select_layer -2 \
    --mm_use_im_start_end False \
    --mm_use_im_patch_token False \
    --fp16 True \
    --output_dir ./checkpoint/PSALM \
    --num_train_epochs 10 \
    --per_device_train_batch_size 4 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 1 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 15000 \
    --save_total_limit 1 \
    --learning_rate 6e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.03 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --tf32 False \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --dataloader_num_workers 4 \
    --lazy_preprocess True \
    --report_to none \
    --seg_task 'panoptic'
